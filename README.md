# è¾“å…¥æ³•çš®è‚¤ç”Ÿæˆ{ignore=true}

[TOC]

## 1. é˜¶æ®µ1

### ğŸ˜€ æ–¹æ¡ˆç¡®å®š

- ç¡®å®šæ–¹æ¡ˆä¸ºä½¿ç”¨ Controlnet æ§åˆ¶å›¾ç‰‡ç”Ÿæˆ

- æ—¨åœ¨è¾¾åˆ°å›¾ä¸­æ•ˆæœï¼Œæ ¹æ®æ§åˆ¶å›¾ç‰‡çš„è§„èŒƒç”Ÿæˆå›¾ç‰‡çš„è½®å»“ï¼Œç»†èŠ‚äº¤ç”±æ¨¡å‹è‡ªå·±ç”Ÿæˆ

<img src="./README_files/fig1.jpg" width="500" height="500">

### ğŸ˜€ æ–¹æ¡ˆéªŒè¯

#### âš™å‰æœŸå‡†å¤‡

- ç¯å¢ƒé…ç½®
```sh
python = 3.10
torch = 1.13.1+cu117
pip install requirements.txt -r
```
or

copy kunhu10 condaåˆ›å»ºçš„ `diff` è™šæ‹Ÿç¯å¢ƒ

- diffusion åŸºç¡€æ¨¡å‹ä¸º stable-diffusion-xl-base-1.0
å­˜å‚¨åœ¨ `/train21/intellQA/permanent/kunhu10/diffusers-main/base_models/stable-diffusion-xl-base-1.0`

- å›¾ç‰‡ caption æ¨¡å‹ Blip æ¨¡å‹å­˜å‚¨åœ¨ `/train21/intellQA/permanent/kunhu10/diffusers-main/base_models/blip-image-captioning-large`

#### ğŸ“•æ•°æ®é›†å‡†å¤‡

- ä¸ºäº†ç¡®å®š [diffusers](https://github.com/huggingface/diffusers) (`diffusers-main/examples/controlnet/train_controlnet_sdxl.py`) ä»£ç çš„å¯è¡Œæ€§ï¼Œä½¿ç”¨ `fill50k` æ•°æ®é›†è¿›è¡Œäº†éªŒè¯

- è¯¥æ•°æ®é›†å…·æœ‰å¦‚ä¸‹æ ¼å¼ï¼Œç›®æ ‡å›¾ç‰‡ï¼Œæ§åˆ¶å›¾ç‰‡ï¼Œä»¥åŠæ–‡æœ¬æè¿°æ–‡ä»¶ `train.jsonl`ï¼Œå¦‚ä¸‹

`{"text": "pale golden rod circle with old lace background", "image": "images/0.png", "conditioning_image": "conditioning_images/0.png"}`
<img src="./README_files/images0.png" width="200" height="200">&nbsp;&nbsp;<img src="./README_files/conditioning_images0.png" width="200" height="200">

- ä¿å­˜åœ¨ `/train21/intellQA/permanent/kunhu10/diffusers-main/dataset/controlnet/fill50k/`ä¸­ï¼Œå…¶ä¸­åŒ…æ‹¬å¦‚ä¸‹æ–‡ä»¶
```
-fill50k\
---conditioning_image\
---iamges\
---fill50k.py
---train.jsonl
```

- ç”±äºæ•°æ®ä¸‹è½½åœ¨æœ¬åœ°ï¼Œå¯¹ `fill50k.py` è¿›è¡Œä¿®æ”¹ç»™å®šæ•°æ®å­˜å‚¨è·¯å¾„:
<img src="./README_files/fill50kpy.png" width="800" height="80">

- åŠ è½½æ•°æ®é›†æ—¶ä½¿ç”¨ `dataset` ä¸­çš„ `load_dataset` æ–¹æ³•åŠ è½½
```py
from datasets import load_dataset

dataset = load_dataset(train_data_dir)
```

#### æ¨¡å‹è®­ç»ƒ

- å¯¹è®­ç»ƒä»£ç æ— éœ€è¿›è¡Œä¿®æ”¹ï¼Œåªéœ€è¦åœ¨è„šæœ¬æ–‡ä»¶ `controlnet.sh` æ–‡ä»¶ä¸­ä¿®æ”¹æ•°æ®é›†è·¯å¾„ `train_data_dir` ä¸ºå¯¹åº” `py` æ–‡ä»¶ä½ç½®ï¼Œè„šæœ¬æ–‡ä»¶ä½ç½® `/train21/intellQA/permanent/kunhu10/diffusers-main/controlnet.sh`
<img src="./README_files/run_sh.png" width="800" height="220">

ğŸ¤—**è®­ç»ƒä»£ç è§£é‡Š: train_controlnet_sdxl.py** 

- line 66-164: `def log_validation()`
  è‹¥åœ¨è®­ç»ƒè„šæœ¬ä¸­æ·»åŠ éªŒè¯promptä»¥åŠconditioning_imagesï¼Œåˆ™åœ¨è¾¾åˆ°éªŒè¯ step æ—¶è°ƒç”¨è¯¥å‡½æ•°ï¼Œæ¨ç†å‡ºå›¾éªŒè¯ç»“æœï¼Œå¹¶åŠ è½½åˆ° log ä¸­
- line 166-184: `def import_model_class_from_model_name_or_path()`
  ç»™å®šä¸‹è½½çš„æ¨¡å‹æƒé‡è·¯å¾„ï¼ŒåŠ è½½æ¨¡å‹
- line 224-591: `def parse_args()` 
  å®šä¹‰å‘½ä»¤è¡Œå‚æ•°ï¼Œé™¤äº†è®­ç»ƒçš„é»˜è®¤è¶…å‚æ•°å¤–ï¼Œéœ€è¦æ³¨æ„ç»™å®šäº†åŠ è½½æ•°æ®é›†æ—¶é»˜è®¤çš„åˆ—åç§°
  <img src="./README_files/args.png" width="600" height="200">
  è¿™ä¸ `train.jsonl` ä¸­å„ä¸ªæ•°æ®é”®å€¼å¯¹çš„åç§°å¯¹åº”
- line: 593-668: `def get_train_dataset()`
  ä½¿ç”¨ `load_dataset` æ–¹æ³•ä»¥åŠ `image_column` `text_column` `conditioning_column` åŠ è½½æ•°æ®ï¼Œè¿”å›åˆå§‹æ•°æ®é›†
  <img src="./README_files/get_dataset.png" width="600" height="260">
- line 671-709: `def encode_prompt(prompt_batch,text_encoders)`
  æ­¤å‡½æ•°æ—¨åœ¨å°†æ–‡æœ¬è¾“å…¥è½¬æ¢ä¸º embeddingï¼Œç»™å®š batch å†…çš„ prompt æ–‡æœ¬ï¼Œ ä½¿ç”¨ `text_encoder` è½¬æ¢ä¸ºæ–‡æœ¬ç‰¹å¾
- line 711-745: `def prepare_train_dataset()`
  å¯¹æ•°æ®é›†è¿›ä¸€æ­¥å¤„ç†ï¼ŒåŒ…æ‹¬å¯¹ image æ•°æ®å½’ä¸€åŒ–ä»¥åŠè½¬æ¢ä¸º tensor
  <img src="./README_files/prepare_dataset.png" width="600" height="250">
- line 747-765: `def collate_fn()`
  åŠ è½½ dataloader çš„æ–¹æ³•ï¼Œç»™å‡ºäº† batch ä¸­å­˜åœ¨ `pixel_values, conditioning_pixel_values, prompt_ids, unet_added_conditions` 
- line 767-1246: `main()` å‡½æ•°
- line 807-887: é€šè¿‡ä¸‹è½½çš„æ¨¡å‹æƒé‡åŠ è½½æ¨¡å‹å¦‚ `text_encoder`,`noise_scheduler`,`vae`,`unet`,`controlnet`, å¹¶æŒ‡å®šåªè®­ç»ƒ `controlnet` éƒ¨åˆ†çš„å‚æ•°
  ```py
  vae.requires_grad_(False)
  unet.requires_grad_(False)
  text_encoder_one.requires_grad_(False)
  text_encoder_two.requires_grad_(False)
  controlnet.train()
  ```
- line 971-993: å®šä¹‰äº† `compute_embeddings()` å‡½æ•°ï¼Œä½¿ç”¨ `encode_prompt()` å‡½æ•°å¯¹æ–‡æœ¬éƒ¨åˆ†è®¡ç®— embeddings å¹¶åŠ è½½è¿›æ•°æ®é›†
  <img src="./README_files/compute_embeddings.png" width="600" height="320">
- line 996-1026: æ„å»ºæ•°æ®é›†ä»¥åŠç”¨äºè®­ç»ƒçš„ dataloader
  <img src="./README_files/train_dataloader.png" width="600" height="460">
- line 1068-1116: prepare to trainï¼Œprintè®­ç»ƒå‚æ•°, è®­ç»ƒè¿›ç¨‹bar
- line 1117-1223: åŠ è½½ batch å†…æ•°æ®å¼€å§‹è®­ç»ƒï¼Œéšæœºé€‰æ‹©ä¸€ä¸ª stepï¼Œå¹¶é¢„æµ‹è¯¥æ­¥çš„å™ªå£°ï¼Œä½¿ç”¨mseæŸå¤±å‡½æ•°ï¼Œä»¥åŠåå‘ä¼ æ’­è¿‡ç¨‹
- <img src="./README_files/start_train_.png" width="600" height="440">
  <img src="./README_files/start_train.png" width="600" height="440">


## 2. é˜¶æ®µ2

### ğŸ˜€ å®éªŒä¸€ï¼šå…¨é”®ç›˜çš®è‚¤æ•°æ®è®­ç»ƒ

#### ğŸ“•æ•°æ®é›†å‡†å¤‡

- é€‰å–26é”®æ•´ä¸ªæ•´ç›˜çš„çš®è‚¤ï¼Œç»Ÿä¸€ reshape ä¸º 512Ã—512 åˆ†è¾¨ç‡å¤§å°ï¼Œå¹¶æè¾¹å‡ºconditioning_image å¦‚ä¸‹
<img src="./README_files/wholekeyboard.png" width="300" height="300"> &nbsp;&nbsp;<img src="./README_files/wholekeyboard_c.png" width="300" height="300">

- æè¾¹æ–¹æ³•ä½¿ç”¨è½®å»“æ£€æµ‹æ–¹æ³•ï¼Œ`cv2.Canny`ï¼Œæ§åˆ¶å›¾ç‰‡ä¹Ÿè¦è°ƒæ•´ä¸ºåŒæ ·å¤§å°åˆ†è¾¨ç‡ï¼Œæ‰€æœ‰ç›®æ ‡å›¾ç‰‡éƒ½ä½¿ç”¨äº†åŒä¸€å¼ æ§åˆ¶å›¾ç‰‡
```py
import cv2
from PIL import Image
image = cv2.imread("./..")
low_threshold = 50
high_threshold = 80
canny_image = cv2.Canny(image,low_threshold,high_threshold)
```

- æ‰€æœ‰æ•°æ®å­˜å‚¨åœ¨ `/train21/intellQA/permanent/kunhu10/diffusers-main/dataset/controlnet/keyboard_50/`,åŒ…å«å¦‚ä¸‹æ–‡ä»¶
<img src="./README_files/keyboard50.png" width="290" height="150">

- å…¶ä¸­ `keyboard_50.py` ä¸­åŒæ ·ä¿®æ”¹äº†`metadata_path`ï¼Œ`images_dir` ä»¥åŠ `conditioning_images_dir`

- å¯¹äºå›¾ç‰‡çš„æ–‡æœ¬æ ‡ç­¾ï¼Œä½¿ç”¨ Blip æ¨¡å‹è¿›è¡Œæ³¨é‡Šï¼Œå°†æ–‡æœ¬æ³¨é‡Šä¿å­˜åœ¨ `train.jsonl` ä¸­ï¼Œå®ç°
```py
from PIL import Image
from transformers import BlipProcessor, BlipForConditionalGeneration
import os
processor = BlipProcessor.from_pretrained("/train21/intell0A/permanent/kunhu10/diffusers-main/base_models/blip-image-captioning-large")
model = BlipForConditionalGeneration.from_pretrained("/train21/intellQA/permanent/kunhu10/diffusers-main/ \\
base_models/blip-image-captioning-large").to("cuda:0")

dataset_path = './dataset/controlnet/keyboard_102/images/'
image_list = []
text_list = []
for i in range(0,102):
    raw_image = Image.open(dataset_path + f'{i}.png')
    image_list.append(raw_image)
    text_list.append("a keyboard skin of")
inputs = processor(image_list, text_list, return_tensors="pt").to("cuda:2")
out = model.generate(**inputs)
import json
# ç”Ÿæˆjsonlæ–‡ä»¶
output_json_path = './dataset/controlnet/keyboard_102/train.jsonl'
new_jsonl = []
# éå†æ¯ä¸€å¼ å›¾ç‰‡çš„"image"
for i in range(len(out)):
    image_info = {"text": processor.decode(out[i], skip_special_tokens=True)+",iflyskin", "image": f"images/{i}.png",\\
    "conditioning_image": f"conditioning_images/{i}.png"}
    new_jsonl.append(image_info)
# å°†jsonlæ•°æ®å†™å…¥åˆ°jsonlæ–‡ä»¶ä¸­
with open(output_json_path, 'w') as json_file:
    for image_info in new_jsonl:
        json_line = json.dumps(image_info, indent=None)
        json_file.write(json_line + '\n')
```
å…·ä½“å¯å‚è€ƒ `/train21/intellQA/permanent/kunhu10/diffusers-main/caption.py` æ–‡ä»¶


#### æ¨¡å‹è®­ç»ƒ

- æ›´æ”¹ `controlnet.sh` ä¸­çš„æ•°æ®é›†è·¯å¾„ `train_data_dir` å³å¯è®­ç»ƒï¼Œè®­ç»ƒä»£ç ä¸åšä¿®æ”¹

#### å®éªŒç»“æœ

- `diffusers-main` ä¸­å°è£…å¥½äº†ç”¨äºæ¨ç†æ­¥éª¤çš„ pipeline ç”¨äºç”Ÿæˆå›¾ç‰‡ï¼Œä½¿ç”¨æ–¹æ³•å¦‚ä¸‹ï¼š
```py
from diffusers import StableDiffusionXLControlNetPipeline, ControlNetModel, UniPCMultistepScheduler
from diffusers.utils import load_image
import torch

base_model_path = "/train21/intellQA/permanent/kunhu10/diffusers-main/base_models/stable-diffusion-xl-base-1.0
controlnet_path = "/train21/intellQA/permanent/kunhu10/diffusers-main/saved_models/controlnet_sdxl/test_version_24/checkpoint-16000/controlnet"  # å¾…æµ‹è¯•çš„controlnetä¿å­˜ä½ç½®
controlnet = ControlNetModel.from_pretrained(controlnet_path, torch_dtype=torch.float16) #åŠ è½½controlnet
pipe = StableDiffusionXLControlNetPipeline.from_pretrained(
    base_model_path, controlnet=controlnet, torch_dtype=torch.float16
)
pipe.to("cuda")
# speed up diffusion process with faster scheduler and memory optimization
pipe.scheduler = UniPCMultistepScheduler.from_config(pipe.scheduler.config)
# remove following line if xformers is not installed or when using Torch 2.0
pipe.enable_xformers_memory_efficient_attention()
# memory optimization
pipe.enable_model_cpu_offload()
prompt = "a picture of ..."
control_image = load_image("....")
generator = torch.manual_seed(0)
image = pipe(
    prompt=prompt,image=control_image,num_inference_steps=20,generator=generator
).images[0]
```

- StableDiffusionXLControlNetPipeline è¿˜æ”¯æŒåŒ…æ‹¬tensorç±»å‹çš„text_embedsï¼Œä»¥åŠimage_embeds ç­‰å¤šç§è¾“å…¥ï¼Œè¾“å‡ºç±»å‹ä¹Ÿæœ‰ tensor, numpy_array, image å¤šç§ï¼Œå…·ä½“å¯æŸ¥çœ‹ `/train21/intellQA/permanent/kunhu10/diffusers-main/src/diffusers/pipelines/controlnet/pipeline_controlnet_sd_xl.py` ä¸­å®šä¹‰çš„ `StableDiffusionXLControlnetPipeline`ç±»

- æ‰¹é‡æ¨ç†å›¾ç‰‡ `/train21/intellQA/permanent/kunhu10/diffusers-main/inferece.py` ä¸­å®ç°

- åœ¨ä½¿ç”¨ 50 å¼ è¾ƒå¥½å›¾ç‰‡è®­ç»ƒ 3000 step ä»¥åŠ 6000 step çš„ç»“æœå¦‚ä¸‹
<img src="./README_files/wholekeyboard_result.png" width="300" height="300"> &nbsp;&nbsp;<img src="./README_files/wholekeyboard_result2.png" width="300" height="300">


### ğŸ˜€ å®éªŒäºŒï¼šåˆ†å—é”®ç›˜çš®è‚¤æ•°æ®è®­ç»ƒ

#### ğŸ“•æ•°æ®é›†å‡†å¤‡

- é‰´äºå…¨é”®ç›˜çš®è‚¤éš¾ä»¥ä½¿ç”¨ï¼Œæä¾›æ•°æ®ä¸­åŒ…æ‹¬ç›¸å½“ä¸€éƒ¨åˆ†å°†é”®ç›˜çš®è‚¤åˆ‡åˆ†æˆå¦‚ä¸‹å››å—çš„æ–°è§„èŒƒ
<img src="./README_files/4parts_keyboard.png" width="300" height="300">

ğŸ¤—**ä½¿ç”¨åŒä¸€ conditioning_image**

- æ”¶é›†è¯¥ç±»çš®è‚¤æ•°æ®å¹¶ç»Ÿä¸€å¤§å°ï¼Œå…±æ”¶é›† 2000 å¼ ï¼Œä¿å­˜äº `/train21/intellQA/permanent/kunhu10/diffusers-main/dataset/controlnet/keyboard2k` ä¸­

- åœ¨ `keyboard2k` æ•°æ®é›†ä¸‹ï¼Œä½¿ç”¨çš„æ§åˆ¶å›¾ç‰‡éƒ½æ˜¯ä¸‹é¢çš„ **åŒä¸€å¼ **ï¼Œæ—¨åœ¨é€šè¿‡åŒä¸€å¼ æ§åˆ¶å›¾ç‰‡å›å½’åˆ°ä¸åŒçš„çš®è‚¤ï¼Œå¢å¼ºçš®è‚¤ç”Ÿæˆçš„å¤šæ ·æ€§
<img src="./README_files/4parts_keyboard_c.png" width="300" height="300">

-  `/train21/intellQA/permanent/kunhu10/diffusers-main/dataset/controlnet/keyboard2k/keyboard2k.py` å¯¹æ•°æ®é›†è·¯å¾„å·²ç»è¿›è¡Œäº†ä¿®æ”¹
  
- ç”±äº 2k å¼ å›¾ç‰‡ä¸­å¤§éƒ¨åˆ†ä¸åŒéƒ¨åˆ†çš„å›¾å±‚å åŠ ä¸æ­£ç¡®ï¼Œåˆé‡æ–°ç­›é€‰äº†å¯¹åº”å…³ç³»è¾ƒå¥½çš„æ•°æ®ï¼Œå…±102å¼  (åº•å›¾åæ˜ åœ¨é¢„è§ˆå›¾ä¸Šï¼Œä¸”å…·æœ‰é”®ç›˜æ ·å¼)ï¼Œæ•°æ®æ–‡ä»¶ä»¥åŠæ•°æ®é›†æ„å»ºæ–¹æ³•åœ¨  `/train21/intellQA/permanent/kunhu10/diffusers-main/dataset/controlnet/keyboard_102/` ä¸­

ğŸ¤—**conditioning_image æ¸²æŸ“æ–‡å­—**

- å°è¯•åœ¨æ§åˆ¶å›¾ç‰‡ä¸Šæ¸²æŸ“ä¸Šç›®æ ‡å›¾ç‰‡çš„æ–‡å­—ï¼Œè¾¾åˆ°ç”Ÿæˆçš®è‚¤ä¸­æŒ‰è¦æ±‚å‡ºç°æ–‡å­—çš„ç›®çš„
- ä½¿ç”¨ paddle OCR æ£€æµ‹å‡ºæ–‡æœ¬æ‰€åœ¨ box ä»¥åŠæ–‡æœ¬ï¼Œå°†å‡†ç¡®åº¦å¤§äº0.98 çš„æ–‡æœ¬æ¸²æŸ“åˆ°ç»Ÿä¸€çš„æè¾¹èƒŒæ™¯ä¸Š
- å®ç°åœ¨ `/train21/intellQA/permanent/kunhu10/GlyphControl/ocr.py` ä¸­ï¼Œä¸»ä½“å¦‚ä¸‹ï¼š
<img src="./README_files/render_back.png" width="800" height="380">
    - å…¶ä¸­ background_path å³ç»Ÿä¸€æè¾¹èƒŒæ™¯å›¾ï¼Œè‹¥è¿è¡Œæ—¶ paddleocr æŠ¥é”™ç¼ºå°‘ `.so` æ–‡ä»¶ç­‰ï¼Œè€ƒè™‘ `module load gcc/xxx` å’Œ `module load cuda/11.7`
    - åœ¨ç¦»çº¿çŠ¶æ€ä¸‹ï¼ŒpaddleOCR æ— æ³•ä¸‹è½½æ–‡æœ¬æ£€æµ‹ä»¥åŠè¯†åˆ«æ¨¡å‹æƒé‡ï¼Œéœ€è¦æ‰‹åŠ¨ä¸‹è½½ï¼Œå¹¶æ›´æ”¹ `tools/infer/utilify.py` ä¸­çš„å‚æ•°ï¼Œå…·ä½“å‚è€ƒ(https://blog.csdn.net/weixin_47151919/article/details/122066480)
  <img src="./README_files/ppocr_param.png" width="700" height="100">

- æ¸²æŸ“æ–‡å­—åçš„æè¾¹å›¾æ„å»ºçš„æ•°æ®é›†ä¿å­˜åœ¨`/train21/intellQA/permanent/kunhu10/diffusers-main/dataset/controlnet/keyboard_102/` ä¸­

#### æ¨¡å‹è®­ç»ƒ

- è®­ç»ƒä»£ç ä¸åšä¿®æ”¹ï¼Œè®­ç»ƒè„šæœ¬ä¸­æ³¨æ„æ›´æ”¹åˆ†è¾¨ç‡å‚æ•° `--resolution`
- å¦‚æœæ˜¯å¾®è°ƒå®éªŒåªéœ€åœ¨è®­ç»ƒè„šæœ¬å‚æ•°ä¸­åŠ ä¸Š `--controlnet_model_name_or_path` ï¼Œä¸ºå¾®è°ƒçš„åŸºç¡€æ¨¡å‹è·¯å¾„
- æŒ‰ç…§ä¸åŒ conditioning_image ä»¥åŠä¸åŒåˆ†è¾¨ç‡è¿›è¡Œäº†ä¸€ç³»åˆ—å®éªŒ

å®éªŒç¼–å·     | type | dataset-size |conditioning-image | resolution | å¤‡æ³¨ |
--------    | -----| -----         |-----              |-----      |----- |
1  | ä»å¤´è®­ç»ƒ | 2k |  æ‰€æœ‰æ•°æ®ä½¿ç”¨åŒä¸€æ§åˆ¶å›¾ | 512 | å¤šæ ·æ€§è¾ƒå¥½ï¼Œå›¾å±‚å åŠ ä¸å¯¹åº”|
2  | ä»å¤´è®­ç»ƒ | 102 | æ‰€æœ‰æ•°æ®ä½¿ç”¨åŒä¸€æ§åˆ¶å›¾| 512 | å›¾å±‚å åŠ å¯¹åº”ï¼Œè®­ç»ƒåˆ°ç¨³å®šç»“æ„åç†è§£æ–‡æœ¬å·®|
3  | å¾®è°ƒ Canny | 102 | æ‰€æœ‰æ•°æ®ä½¿ç”¨åŒä¸€æ§åˆ¶å›¾ | 512 |
4  | ä»å¤´è®­ç»ƒ   | 102 | æ¯å¼ æ§åˆ¶å›¾æ¸²æŸ“å¯¹åº”æ–‡å­—| 1024 |
5  | å¾®è°ƒ Canny | 102 |æ¯å¼ æ§åˆ¶å›¾æ¸²æŸ“å¯¹åº”æ–‡å­—| 1024|ç»“æ„ç¨³å®šæ–‡æœ¬ç†è§£è¾ƒå¥½ï¼Œå¤šæ ·æ€§ä¸€èˆ¬|

#### å®éªŒç»“æœ

- ç¬¦åˆåŸºæœ¬é”®ç›˜è§„èŒƒï¼Œæ¨¡å‹å­¦ä¹ åˆ°ç›¸å…³ç»“æ„å¸ƒå±€ä¿¡æ¯
    <img src="./README_files/4parts_results1.png" width="300" height="300"> &nbsp;&nbsp;<img src="./README_files/4parts_results2.png" width="300" height="300">


## 3. é˜¶æ®µ3

### ğŸ˜€ å®éªŒä¸€ï¼šå…³é”®é”®ç›˜å…ƒç´ å¸ƒå±€çš®è‚¤

- ä¸ºäº†è¿›ä¸€æ­¥é€‚åº”ä½¿ç”¨éœ€æ±‚ï¼Œè¦æ±‚çš®è‚¤å¸ƒå±€ä»…éœ€è¦å…³é”®å…ƒç´ å¦‚å¯¼èˆªæ ï¼ŒåŠŸèƒ½é”®ï¼Œ26é”®ï¼Œ9é”®èƒŒæ™¯ç­‰ï¼Œå¦‚ä¸‹å›¾
  <img src="./README_files/key_elements_ex.png" width="300" height="300">

#### ğŸ“• æ•°æ®å‡†å¤‡

- ä»çš®è‚¤å•†åŸä»¥åŠç¤¾åŒºçš®è‚¤ä¸­ç­›é€‰äº†éƒ¨åˆ†å¯ç”¨æ•°æ®ï¼Œè¿™äº›çš®è‚¤æ˜¯æŒ‰ç…§åè®®ç»„åˆå„ä¸ªå…ƒç´ å›¾ç‰‡è€Œæˆï¼Œå¯¹äºæ¯ä¸ªé”®ç›˜çš®è‚¤ï¼Œæœ‰å¦‚ä¸‹æ–‡ä»¶å¤¹ï¼ŒåŒ…å«äº†å„ä¸ªé”®çš„å›¾ç‰‡æ–‡ä»¶
  <img src="./README_files/key_elements_folder.png" width="400" height="300">
- è¿™äº›æ–‡ä»¶å¤¹ç»Ÿä¸€ä¿å­˜åœ¨ `/train21/intellQA/permanent/kunhu10/GlyphControl/image_path_folder/` ä¸­
- å¸ƒå±€è¿™äº›å…ƒç´ åˆ°åŒä¸€å¼ ç”»å¸ƒä¸Šï¼Œåˆ¶å®šäº†ä¸€å®šçš„è§„åˆ™ (å„ä¸ªåŠŸèƒ½é”®çš„åœ¨ç”»å¸ƒä¸Šçš„ä½ç½®)ï¼Œä¸»è¦å®ç°åœ¨ `load_image` å‡½æ•°ä¸­ï¼Œå®šä¹‰äº†æ¯ä¸ªæŒ‰é”®å…ƒç´ çš„å¤§å°ä»¥åŠä½ç½®
- å®ç°æ–¹å¼åœ¨ `/train21/intellQA/permanent/kunhu10/GlyphControl/merge_image.py` ä¸­
    <img src="./README_files/merge_images.png" width="600" height="450">
- ç»è¿‡ä¸¤æ¬¡æå–ï¼Œä¸€å…±å¾—åˆ° 332 å¼ å¯ç”¨çš®è‚¤ï¼Œconditioning_images ä»¥åŠæ–‡æœ¬æ ‡ç­¾ç­‰æŒ‰ç…§ä¹‹å‰æ–¹æ³•åˆ›å»ºï¼Œä¿å­˜åœ¨ `/train21/intellQA/permanent/kunhu10/diffusers-main/dataset/controlnet/keyboard_332_512/` ä»¥åŠ  `/train21/intellQA/permanent/kunhu10/diffusers-main/dataset/controlnet/keyboard_332_1024/` ä¸­ï¼ŒäºŒè€…åˆ†è¾¨ç‡ä¸åŒ
    <img src="./README_files/key_elements_demo.png" width="300" height="300">

#### æ¨¡å‹è®­ç»ƒ

- è®­ç»ƒæ–¹å¼ä¸ä¹‹å‰ç›¸åŒï¼Œå½“è®­ç»ƒ 1024Ã—1024 çš„å›¾åƒæ—¶ï¼Œéœ€ä½¿ç”¨ 80GB æ˜¾å¡
- å¤šå¡å¹¶è¡Œè®­ç»ƒæ˜¯é€šè¿‡ accelerate å®ç°çš„ï¼Œè®¾ç½®å‚æ•°æ—¶ï¼Œåœ¨å‘½ä»¤è¡Œ `accelerate config` è¿›è¡Œé€‰æ‹©æˆ–è€…åœ¨`home`ç›®å½•ä¸‹æ›´æ”¹ `.cache/huggingface/accelarate/defaut_config.yaml` æ–‡ä»¶ï¼Œå¦‚ä¿®æ”¹ä¸º8å¡å¹¶è¡Œçš„é…ç½®å¦‚ä¸‹
  ```sh
  compute_environment: LOCAL_MACHINE
    distributed_type: MULTI_GPU
    downcast_bf16: 'no'
    gpu_ids: all
    machine_rank: 0
    main_training_function: main
    mixed_precision: 'no'
    num_machines: 1
    num_processes: 8
    rdzv_backend: static
    same_network: false
    tpu_env: []
    tpu_use_cluster: false
    tpu_use_sudo: false
    use_cpu: false
  ```

#### å®éªŒç»“æœ
- ä¸é¢„æœŸç¬¦åˆï¼Œå¸ƒå±€è§„èŒƒï¼Œä½†æ˜¯å›¾ç‰‡ä¸­æ–‡æœ¬éƒ¨åˆ†ä»ç„¶å­˜åœ¨é—®é¢˜
 <img src="./README_files/key_elements_results1.png" width="300" height="300"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<img src="./README_files/key_elements_results2.png" width="300" height="300">


### ğŸ˜€ å®éªŒäºŒï¼šæ·»åŠ ctc-lossç›‘ç£å›¾ç‰‡ä¸­çš„æ–‡æœ¬ç”Ÿæˆ

#### ğŸ“• æ•°æ®å‡†å¤‡

- ç›‘ç£æ˜¯å¦ç”Ÿæˆå¯è¯†åˆ«æ–‡æœ¬ï¼Œæ•°æ®ä¸­éœ€åŒ…å«æ­£ç¡®æ–‡æœ¬çš„æ ‡ç­¾ä»¥åŠå›¾ç‰‡ä¸­æ–‡æœ¬æ‰€åœ¨åŒºåŸŸä¿¡æ¯
- åœ¨ `train.jsonl` æ–‡ä»¶ä¸­è¿›è¡Œäº†ä¿®æ”¹ï¼Œæ­¤æ—¶æ¯ä¸€è¡Œä¸ºå¦‚ä¸‹é”®å€¼å¯¹ï¼Œä¿å­˜åœ¨ `/train21/intellQA/permanent/kunhu10/diffusers-main/dataset/controlnet/keyboard_332_512/`
  ```
  {"text":"a picture of a girl with long hair, iflyskin, writing \"å‰å¾€ \","image":"images/0.png",
  "conditioning_image":"conditioning_images/0.png",
  "box":[[[430.0,174.0],[450.0,174.0],[450.0,186.0],[430.0,186.0]]]}
  ```

- å¯¹æ•°æ®é›†åŠ è½½æ–¹æ³• (`/train21/intellQA/permanent/kunhu10/diffusers-main/dataset/controlnet/keyboard_332_512/keyboard_332_512.py`) è¿›è¡Œä¿®æ”¹ï¼Œæ·»åŠ æ–°çš„æ•°æ®æ ¼å¼å¤šç»´æ•°ç»„
   <img src="./README_files/keyboard_box.png" width="400" height="130">

- å¯¹äºæ•°æ®é›†å‡†å¤‡ä»¥åŠåŠ è½½dataloaderçš„éƒ¨åˆ†è¿›è¡Œä¿®æ”¹ï¼Œä¿å­˜äº `/train21/intellQA/permanent/kunhu10/diffusers-main/train_controlnet_sdxl_own.py` ä¸­
- ä¿®æ”¹ `prepare_train_dataset` å‡½æ•°ä¸­ `process_train` å¦‚ä¸‹ï¼š
  <img src="./README_files/process_train.png" width="700" height="430">
- ä¿®æ”¹ `collate_fn` å‡½æ•°å¦‚ä¸‹ï¼š
  <img src="./README_files/collate_fn.png" width="700" height="330"> 
  å…¶ä¸­ `gt_text,text_length,box` æ˜¯æ¯æ¡æ•°æ®æ–°å¢çš„è¾“å…¥ç±»å‹ï¼Œåˆ†åˆ«è¡¨ç¤ºground-truthçš„æ–‡æœ¬æ ‡ç­¾ï¼Œæ–‡æœ¬é•¿åº¦ä»¥åŠæ–‡æœ¬æ¡†ä½ç½®ï¼Œç”¨äºç›‘ç£æ–‡æœ¬ç”Ÿæˆ

#### æ¨¡å‹è®­ç»ƒ

ğŸ¤—`train_controlnet_sdxl_own.py` **ä¿®æ”¹**
- æ·»åŠ ç”¨äºppocrè¯†åˆ«çš„å­—å…¸ï¼Œå³ä½¿ç”¨ä¸€ä¸ªä¿å­˜äº†å¸¸è§æ±‰å­—ç¬¦çš„æ–‡æœ¬æ–‡ä»¶åˆ›å»ºdict
  <img src="./README_files/dict.png" width="600" height="100">
- åˆå§‹åŒ–äº†ç”¨äºæ–‡æœ¬è¯†åˆ«çš„ppocræ¨¡å‹ï¼Œå…¶ç›¸å…³å®ç°ä»¥åŠæ¨¡å‹æƒé‡ä¿å­˜åœ¨ `/train21/intellQA/permanent/kunhu10/diffusers-main/Anytext/` ä¸­, `text_recognizer` ç”¨äºåç»­åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¯¹ç›‘ç£æ¨ç†å›¾ç‰‡ä¸­çš„æ–‡æœ¬éƒ¨åˆ†
  <img src="./README_files/text_recognize.png" width="650" height="100">
- åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­è¾¹è®­ç»ƒè¾¹æ¨ç†å½“å‰æ¨¡å‹çš„å‡ºå›¾ç»“æœï¼Œä½¿ç”¨ `infer_img` å‡½æ•°å®ç°æ¨ç†è¿‡ç¨‹
  <img src="./README_files/infer_img.png" width="650" height="500">
  ç»™å®šå½“å‰ `batch` ä»¥åŠ `vae`,`unet` (å†»ç»“) ä»¥åŠ `controlnet` (è®­ç»ƒ) æ¨¡å‹ï¼Œå³å¯å¾—åˆ°è¾“å‡º images tensor
- è®¡ç®— ctc_loss çš„å®ç°åœ¨`/train21/intellQA/permanent/kunhu10/diffusers-main/Anytext/recognizer.py` ä¸­ã€‚æœ¬å®éªŒä¸­ä½¿ç”¨ `OCR_ctcloss` å‡½æ•°æ¥æ”¶é¢„æµ‹å›¾ç‰‡ä»¥åŠæ ‡ç­¾è®¡ç®—æŸå¤±
  <img src="./README_files/loss_ctc.png" width="750" height="250">
 
- ä¸€æ¬¡forward è®¡ç®— `loss_ctc` çš„è¿‡ç¨‹å¦‚ä¸‹
  ```py
  for epoch in range(first_epoch,args.num_train_epochs):
        for step,batch in enumerate(train_dataloader):
            infer_images = infer_img(args,accelerator,noise_scheduler,vae,unet,controlnet,weight_dtype,batch)
            preds,loss_text = OCR_ctcloss(infer_images,text_recognizer,bacth)
            loss_text = loss_text.to(accelerator.device)
  ```
- æ¨¡å‹è®­ç»ƒè„šæœ¬æ–‡ä»¶ä¿å­˜ä¸º `/train21/intellQA/permanent/kunhu10/diffusers-main/controlnet_own.sh`

#### å®éªŒç»“æœ

- loss_text éš¾ä»¥ä¸‹é™


## 4. åç»­

- å¢åŠ æ•°æ®é›†å¤§å°ä»å¤´è®­ç»ƒï¼Œæ•°ç™¾ä¸ªæ•°æ®ç›¸å¯¹è¾ƒå°‘
- æ–‡æœ¬æŸå¤±éš¾ä»¥ä¼˜åŒ–ï¼Œå…³æ³¨åç»­ [Anytext](https://github.com/tyxsspa/AnyText) å¼€æºåï¼Œå‚è€ƒå®ç°æ–¹å¼
- SD3 ä½¿ç”¨ transformer æ›¿ä»£ Unet backbone, å¯¹æ–‡æœ¬ç”Ÿæˆå‹å¥½ï¼Œå…³æ³¨åç»­å®ç°å·¥ä½œ


